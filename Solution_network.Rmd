---
title: "Solution_network"
output: html_document
---

# 1.Preliminaries

## 1.1 Install Packages 
```{r}
# 1. List of standard CRAN packages
cran_packages <- c("bnlearn", "igraph", "miic")

# 2. Install and load CRAN packages
for (pkg in cran_packages) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg)
    library(pkg, character.only = TRUE)
  }
}

# 3. Install and load pcalg (via Bioconductor to manage dependencies)
if (!require("BiocManager", quietly = TRUE)) install.packages("BiocManager")
if (!require("pcalg", quietly = TRUE)) BiocManager::install("pcalg")

# 4. Load pcalg
library(pcalg)

# Verify everything is loaded
print("All packages loaded successfully!")
```
## 1.2 Create instance 

```{r}

# 1. Define the model string (Source: bnlearn::insurance help documentation)
# This string represents the "Ground Truth" structure: [Node|Parents]
model_string <- paste0(
  "[Age][Mileage][SocioEcon|Age][GoodStudent|Age:SocioEcon]",
  "[RiskAversion|Age:SocioEcon][OtherCar|SocioEcon]",
  "[VehicleYear|SocioEcon:RiskAversion][MakeModel|SocioEcon:RiskAversion]",
  "[SeniorTrain|Age:RiskAversion][HomeBase|SocioEcon:RiskAversion]",
  "[AntiTheft|SocioEcon:RiskAversion][RuggedAuto|VehicleYear:MakeModel]",
  "[Antilock|VehicleYear:MakeModel][DrivingSkill|Age:SeniorTrain]",
  "[CarValue|VehicleYear:MakeModel:Mileage][Airbag|VehicleYear:MakeModel]",
  "[DrivQuality|RiskAversion:DrivingSkill][Theft|CarValue:HomeBase:AntiTheft]",
  "[Cushioning|RuggedAuto:Airbag][DrivHist|RiskAversion:DrivingSkill]",
  "[Accident|Antilock:Mileage:DrivQuality][ThisCarDam|RuggedAuto:Accident]",
  "[OtherCarCost|Accident][MedCost|Age:Accident:Cushioning]",
  "[ILiCost|Accident][ThisCarCost|ThisCarDam:Theft:CarValue]",
  "[PropCost|ThisCarCost:OtherCarCost]"
)

# 2. Create the network object from the string
ground_truth_dag <- model2network(model_string)

# 3. (Optional) Verify the creation
print(ground_truth_dag)
```

## 1.c the Content of the object (ground_truth_dag)

```{r}
# 1. Check the class of the object
# Expected output: "bn" (Bayesian Network)
class(ground_truth_dag)

# 2. See the content
# This displays the number of nodes, arcs, and the model string
print(ground_truth_dag)
```

## 1.d 

```{r}
# 1. Get the adjacency matrix
amat_true <- bnlearn::amat(ground_truth_dag)

# 2. Check the dimensions 
dim(amat_true)

# 3. View the first few rows and columns to inspect the structure
print(amat_true[1:7, 1:7])
```

## 1.e Building directed graph using igraph 

```{r}
# 1. Build the directed igraph object from the adjacency matrix
# 'mode = "directed"' ensures the arrows point from parent to child
g_true <- graph_from_adjacency_matrix(amat_true, mode = "directed")

# 2. Generate a "Nice" Plot
# We use 'layout_with_graphopt' which effectively un-clutters medium-sized networks
plot(g_true, 
     layout = layout_with_graphopt,   # A force-directed layout that spreads nodes well
     main = "Ground Truth: Insurance Network",
     
     # Node styling
     vertex.color = "lightblue",      # Fill color
     vertex.frame.color = "white",    # Border color
     vertex.size = 10,                # Node size (adjusted for 27 nodes)
     vertex.label.cex = 0.7,          # Label font size (smaller to fit)
     vertex.label.color = "black",    # Label color
     
     # Edge styling
     edge.arrow.size = 0.4,           # Smaller arrows for cleaner look
     edge.color = "darkgray",         # softer edge color
     edge.curved = 0.1                # Slight curve to make connections distinct
)
```
The structural analysis of the ground truth reveals a Directed Acyclic Graph (DAG) organized into distinct causal layers that mirror the logic of car insurance risks. The network begins with top-layer root nodes such as Age, SocioEcon, and Mileage, which function as exogenous variables not caused by other factors in the system. These flow into intermediate nodes representing the mechanisms of the driver's profile and vehicle status, including RiskAversion, DrivingSkill, VehicleYear, Antilock, and RuggedAuto. A critical "collider" in this structure is the Accident node, a central hub where multiple influences—such as Antilock, Mileage, and DrivQuality—converge. Finally, the network terminates at the bottom with leaf nodes that represent the financial consequences, specifically PropCost, MedCost, and ThisCarCost.

# 2. Score-based method

## 2.1 

```{r}
# 2. Load the insurance dataset
data(insurance)

head(insurance)
```
# 2.2

```{r}
# 1. Reconstruct the network using Hill-Climbing
# 'hc' stands for Hill-Climbing, a score-based structure learning algorithm
res_hc <- hc(insurance)

# 2. Check the class of the returned object
# Expected: "bn"
class(res_hc)

# 3. See the content
# This will show the learned edges (arcs) and the score of the network
print(res_hc)
```

# 2.3 

```{r}
# 1. Get the adjacency matrix for the Hill-Climbing result
amat_hc <- bnlearn::amat(res_hc)

# 2. Check the dimensions
# It should still be 27x27 (same nodes as the original data)
dim(amat_hc)

# 3. View the first few rows/cols to check the structure
print(amat_hc[1:7, 1:7])
```

# 2.4 

```{r}
library(igraph)

# 1. Build the directed igraph object
# We use the adjacency matrix 'amat_hc' from the previous step
g_hc <- graph_from_adjacency_matrix(amat_hc, mode = "directed")

# 2. Plot the network
# We use similar parameters to the Ground Truth plot for easy visual comparison
plot(g_hc, 
     layout = layout_with_graphopt,   # Good layout for spreading nodes
     main = "Reconstructed Network (Hill-Climbing)",
     
     # Node styling
     vertex.color = "lightgreen",     # Different color to distinguish from Truth
     vertex.frame.color = "darkgreen",
     vertex.size = 10,
     vertex.label.cex = 0.7,
     vertex.label.color = "black",
     
     # Edge styling
     edge.arrow.size = 0.4,
     edge.color = "gray50",
     edge.curved = 0.1
)
```
The Hill-Climbing (HC) network represents what the algorithm "learned" purely from looking at the data, without knowing the true rules.

Visually, the Hill-Climbing algorithm successfully recovered the general topology (the clusters of nodes are similar). However, the Green plot likely appears slightly "messier" or denser. This visual difference represents the False Positives (correlations mistaken for causation) that score-based algorithms often struggle with.
# 2.5 

```{r}
# --- PRE-PROCESSING: SAFETY CHECK ---
# Ensure the rows and columns are in the EXACT same order before comparing.
# If they are different, the upper.tri comparison will be meaningless.
amat_hc <- amat_hc[rownames(amat_true), colnames(amat_true)]

# 1. Convert Adjacency Matrices to Skeletons (Undirected)
# We check if an edge exists in either direction (A->B OR B->A)
skel_true <- (amat_true + t(amat_true)) > 0
skel_hc   <- (amat_hc   + t(amat_hc))   > 0

# 2. Select only the Upper Triangle
# Since the matrices are now symmetric, we only look at one half 
# to avoid double-counting edges.
ut <- upper.tri(skel_true)

# 3. Calculate Counts (TP, FP, FN)
TP <- sum(skel_hc[ut] & skel_true[ut])   # Edge in BOTH
FP <- sum(skel_hc[ut] & !skel_true[ut])  # Edge in HC only
FN <- sum(!skel_hc[ut] & skel_true[ut])  # Edge in Truth only

# 4. Compute Metrics (with safety for division by zero)
# If (TP+FP) is 0, Precision is 0 (to avoid NaN)
precision <- if((TP + FP) == 0) 0 else TP / (TP + FP)

# If (TP+FN) is 0, Recall is 0
recall    <- if((TP + FN) == 0) 0 else TP / (TP + FN)

# If Precision + Recall is 0, F-score is 0
fscore    <- if((precision + recall) == 0) 0 else 2 * (precision * recall) / (precision + recall)

# 5. Print Results
cat("====================================\n")
cat("Skeleton Evaluation Results\n")
cat("====================================\n")
cat("True Positives (TP):", TP, "\n")
cat("False Positives (FP):", FP, "\n")
cat("False Negatives (FN):", FN, "\n")
cat("----------------------------\n")
cat("Precision:", round(precision, 4), "\n")
cat("Recall:   ", round(recall, 4), "\n")
cat("F-score:  ", round(fscore, 4), "\n")
```

The Hill-Climbing algorithm achieved a reasonably good reconstruction of the network structure, recovering the majority of the true connections (37 edges) with a balanced F-score of 0.73. However, the results highlight a common limitation of score-based methods: the algorithm struggled to distinguish direct causal links from indirect correlations, leading to 13 false positive edges that do not exist in the ground truth. Simultaneously, it failed to capture about 27% of the true structure (14 false negatives), likely missing weaker dependencies or complex relationships that the scoring metric could not justify adding based on the data alone.

# 2.6 

```{r}
# 1. Define the edge colors based on validity
# We iterate through every edge in the learned graph (g_hc)
edge_list_hc <- as_edgelist(g_hc)

# Initialize a vector of colors (default to gray/correct)
edge_colors <- rep("gray50", nrow(edge_list_hc))
edge_widths <- rep(1, nrow(edge_list_hc))

# 2. Check each edge against the Ground Truth Skeleton
for (i in 1:nrow(edge_list_hc)) {
  node_a <- edge_list_hc[i, 1]
  node_b <- edge_list_hc[i, 2]
  
  # Check if this connection exists in the truth (undirected check)
  # skel_true was defined in the previous step
  if (skel_true[node_a, node_b] == 0) {
    # If not in truth, it is a False Positive -> Color RED
    edge_colors[i] <- "red"
    edge_widths[i] <- 2.5  # Make it thicker
  }
}

# 3. Assign attributes to the graph
E(g_hc)$color <- edge_colors
E(g_hc)$width <- edge_widths

# 4. Plot the network with highlighted FPs
plot(g_hc, 
     layout = layout_with_graphopt, 
     main = "Hill-Climbing: False Positives (Red)",
     
     # Node styling
     vertex.color = "white",
     vertex.frame.color = "black",
     vertex.size = 8,
     vertex.label.cex = 0.6,
     vertex.label.color = "black",
     
     # Edge styling (arrow size)
     edge.arrow.size = 0.4
)

# Add a simple legend
legend("topleft", legend=c("Correct (TP)", "False Positive (FP)"), 
       col=c("gray50", "red"), lty=1, lwd=c(1, 2.5), cex=0.8)
```
# 2.g 

```{r}
# 1. Calculate Structural Hamming Distance (SHD)
# This compares the learned DAG (res_hc) directly to the ground truth (ground_truth_dag)
# Use bnlearn::shd to avoid conflict with pcalg
dist_shd <- bnlearn::shd(res_hc, ground_truth_dag)

cat("Structural Hamming Distance (SHD):", dist_shd, "\n")
# Note: Lower is better. 0 means a perfect match.

# 2. Compare using CPDAGs (Equivalence Classes)
# This is often considered a "fairer" comparison for structure learning
cpdag_true <- cpdag(ground_truth_dag)
cpdag_hc   <- cpdag(res_hc)

dist_shd_cpdag <- bnlearn::shd(cpdag_hc, cpdag_true)
cat("SHD between Equivalence Classes:", dist_shd_cpdag, "\n")

# If you want to manually count how many edges have the WRONG orientation 
# 3. Simple Orientation Count (Manual Calculation)
# (but correct skeleton):
amat_true <- amat(ground_truth_dag)
amat_hc   <- amat(res_hc)

# Find edges that exist in both (Common Skeleton)
common_skeleton <- (amat_true == 1 | t(amat_true) == 1) & 
                   (amat_hc == 1   | t(amat_hc) == 1)

# Check which of these common edges are flipped
# (Exists in HC as A->B, but in Truth as B->A)
reversed_edges <- sum(amat_hc == 1 & t(amat_true) == 1 & common_skeleton)

cat("Number of edges with reversed orientation:", reversed_edges, "\n")
```
The high Structural Hamming Distance (SHD) of 48 reveals significant discrepancies between the reconstructed network and the ground truth, indicating that the model requires nearly as many corrections as there are total edges in the true graph. However, the low number of reversed edges (4) demonstrates that when the algorithm successfully detects a connection, it is highly accurate at determining the causal direction. The fact that the SHD did not improve when comparing equivalence classes confirms that the poor performance is driven by fundamental errors in the skeleton (missing or extra edges) rather than harmless statistical ambiguities in edge orientation.

# 3. Constraint-based method (PC)

```{r}
insurance_num <- data.matrix(insurance)

# B. Make the categories start from 0
# R uses 1-based indexing for factors, but pcalg (C++ backend) expects 0-based.
insurance_num <- insurance_num - 1

# C. Compute the number of levels for each variable
# Since we shifted to start at 0, the number of levels is the max value + 1.
n_lev <- apply(insurance_num, 2, max) + 1

# D. Prepare the suffStat object
# The 'disCItest' requires the data matrix (dm) and the number of levels (nlev).
suffStat <- list(dm = insurance_num, nlev = n_lev, adaptDF = FALSE)

# --- 2. Reconstruct Network (PC Algorithm) ---

# We run the PC algorithm with:
# - indepTest = disCItest (Discrete Conditional Independence Test)
# - alpha = 0.01 (Standard significance level, adjust if needed)
pc_fit <- pc(suffStat, 
             indepTest = disCItest, 
             alpha = 0.01, 
             labels = colnames(insurance), 
             verbose = FALSE)

# Check the result
print(pc_fit)
```

## 3.2

```{r}
# Since pc_fit is a 'pcalg' object, we coerce it to an adjacency matrix directly.
amat_pc <- as(pc_fit, "amat")

# 2. Check the dimensions (Should be 27x27)
dim(amat_pc)

# 3. View the first few rows
print(amat_pc[1:7, 1:7])
```

## 3.3

```{r}

# 1. Build the igraph object
# The PC matrix contains 1s for edges.
# If amat[A,B]=1 and amat[B,A]=1, it is undirected.
# If amat[A,B]=1 and amat[B,A]=0, it is directed A->B.
g_pc <- graph_from_adjacency_matrix(amat_pc, mode = "directed")

# 2. Plotting
plot(g_pc, 
     layout = layout_with_graphopt, 
     main = "Reconstructed Network (PC Algorithm)",
     
     # Node styling
     vertex.color = "lightblue",
     vertex.frame.color = "darkblue",
     vertex.size = 10,
     vertex.label.cex = 0.7,
     vertex.label.color = "black",
     
     # Edge styling
     # Bi-directed edges (undirected) will show as lines with arrows at both ends 
     # or two separate lines depending on igraph version default.
     edge.arrow.size = 0.4,
     edge.color = "gray40",
     edge.curved = 0.1
)
```

## 3.4 

```{r}
# --- PRE-PROCESSING: ALIGNMENT ---
# Ensure rows/cols of the learned PC matrix match the Ground Truth order
amat_pc <- amat_pc[rownames(amat_true), colnames(amat_true)]

# 1. Convert to Skeletons (Undirected)
# Logic: If edge exists A->B OR B->A, it counts as a connection.
# For PC: Undirected edges have 1s in both [A,B] and [B,A], which works perfectly here.
skel_true <- (amat_true + t(amat_true)) > 0
skel_pc   <- (amat_pc   + t(amat_pc))   > 0

# 2. Select Upper Triangle
# To avoid double counting symmetric edges
ut <- upper.tri(skel_true)

# 3. Calculate Counts
TP <- sum(skel_pc[ut] & skel_true[ut])   # Edge exists in BOTH
FP <- sum(skel_pc[ut] & !skel_true[ut])  # Edge in PC but NOT Truth
FN <- sum(!skel_pc[ut] & skel_true[ut])  # Edge in Truth but NOT PC

# 4. Compute Metrics (with 0-division safety)
precision <- if((TP + FP) == 0) 0 else TP / (TP + FP)
recall    <- if((TP + FN) == 0) 0 else TP / (TP + FN)
fscore    <- if((precision + recall) == 0) 0 else 2 * (precision * recall) / (precision + recall)

# 5. Print Results
cat("====================================\n")
cat("PC Algorithm: Skeleton Evaluation\n")
cat("====================================\n")
cat("True Positives (TP):", TP, "\n")
cat("False Positives (FP):", FP, "\n")
cat("False Negatives (FN):", FN, "\n")
cat("----------------------------\n")
cat("Precision:", round(precision, 4), "\n")
cat("Recall:   ", round(recall, 4), "\n")
cat("F-score:  ", round(fscore, 4), "\n")
```
1. Overall Assessment: "Clean but Incomplete" The most striking result is the Precision of 1.0 (100%).

    False Positives (FP) = 0: This is an exceptional result. Every single edge the algorithm found actually exists in the Ground Truth. The PC algorithm did not "hallucinate" any incorrect connections.

    Implication: You can trust the edges that are present implicitly. If the PC algorithm draws a line between two nodes, that relationship is almost certainly real.

2. The Trade-off: Low Recall

    False Negatives (FN) = 24 (Recall ~53%): The algorithm missed nearly half of the true connections in the network.

    Cause: The PC algorithm is conservative. It performs statistical tests (conditional independence tests) to verify edges. If the data is noisy or the relationship between two variables is weak, the statistical test fails to reject independence, and the algorithm conservatively removes the edge. It prefers to miss a connection rather than guess incorrectly.

3. Comparison with Hill-Climbing (HC) This creates a distinct contrast with the previous Score-based results:

    Hill-Climbing (Score-based): Was "Greedy." It found more true edges (TP=37 vs 27) but
    dded significant noise (13 False Positives). It prioritizes maximizing a score, even at the cost of errors.

    PC Algorithm (Constraint-based): Is "Cautious." It found fewer edges (TP=27), but made zero mistakes on the ones it found.
    
4. Imrpoving results 

    We can imrpove the results by trying different parameters

Conclusion The PC algorithm produced a sparse but highly reliable skeleton. While it yielded a slightly lower F-score (0.69) compared to Hill-Climbing (0.73) due to low Recall, it is arguably more valuable if the priority is avoiding false leads. In a practical scenario, this graph provides a set of 27 high-confidence connections, acknowledging that many weaker relationships remain undetected.


## 3.e Highlited the FP:
in this algorithm we got 0 FP so there is nothing to highlight

#4. Local search method (aracne)

##4.a 

```{r}
res_aracne <- aracne(insurance)

# 2. Check the class
# Expected: "bn"
class(res_aracne)

# 3. View the content
# Note: ARACNE returns an undirected graph (arcs will appear as A - B)
print(res_aracne)
```

## 4.b 

```{r}
# 1. Get the adjacency matrix
amat_aracne <- bnlearn::amat(res_aracne)

# 2. Check the dimensions (should be 27x27)
dim(amat_aracne)

# 3. View the first few rows
print(amat_aracne[1:7, 1:7])
```

## 4.c 

```{r}
library(igraph)

# 1. Build the igraph object
# We use mode = "directed" as requested, but since ARACNE is undirected, 
# you will see bidirectional edges (or lines with no clear single direction).
g_aracne <- graph_from_adjacency_matrix(amat_aracne, mode = "directed")

# 2. Plotting
plot(g_aracne, 
     layout = layout_with_graphopt, 
     main = "Reconstructed Network (ARACNE)",
     
     # Node styling
     vertex.color = "lightyellow",     # Distinct color for ARACNE
     vertex.frame.color = "orange",
     vertex.size = 10,
     vertex.label.cex = 0.7,
     vertex.label.color = "black",
     
     # Edge styling
     edge.arrow.size = 0.3,
     edge.color = "gray40",
     edge.curved = 0.1
)
```
## 4.e 

```{r}
# --- PRE-PROCESSING: ALIGNMENT ---
# Ensure rows/cols of the learned ARACNE matrix match the Ground Truth order
amat_aracne <- amat_aracne[rownames(amat_true), colnames(amat_true)]

# 1. Convert to Skeletons (Undirected)
# Check if an edge exists in either direction.
# Since ARACNE creates symmetric matrices, this just confirms it implies existence.
skel_true   <- (amat_true + t(amat_true)) > 0
skel_aracne <- (amat_aracne + t(amat_aracne)) > 0

# 2. Select Upper Triangle
# Only look at unique pairs to avoid double counting
ut <- upper.tri(skel_true)

# 3. Calculate Counts
TP <- sum(skel_aracne[ut] & skel_true[ut])   # Edge in BOTH
FP <- sum(skel_aracne[ut] & !skel_true[ut])  # Edge in ARACNE only
FN <- sum(!skel_aracne[ut] & skel_true[ut])  # Edge in Truth only

# 4. Compute Metrics (with safety checks)
precision <- if((TP + FP) == 0) 0 else TP / (TP + FP)
recall    <- if((TP + FN) == 0) 0 else TP / (TP + FN)
fscore    <- if((precision + recall) == 0) 0 else 2 * (precision * recall) / (precision + recall)

# 5. Print Results
cat("====================================\n")
cat("ARACNE: Skeleton Evaluation\n")
cat("====================================\n")
cat("True Positives (TP):", TP, "\n")
cat("False Positives (FP):", FP, "\n")
cat("False Negatives (FN):", FN, "\n")
cat("----------------------------\n")
cat("Precision:", round(precision, 4), "\n")
cat("Recall:   ", round(recall, 4), "\n")
cat("F-score:  ", round(fscore, 4), "\n")

```

## 5.e

```{r}
# 1. Define Edge Colors based on False Positives
# We iterate through every edge in the ARACNE graph
edge_list_aracne <- as_edgelist(g_aracne)

# Initialize vectors for color and width
edge_colors <- rep("gray50", nrow(edge_list_aracne))
edge_widths <- rep(1, nrow(edge_list_aracne))

# 2. Check each edge against the Ground Truth Skeleton
for (i in 1:nrow(edge_list_aracne)) {
  node_a <- edge_list_aracne[i, 1]
  node_b <- edge_list_aracne[i, 2]
  
  # Check existence in Truth Skeleton (skel_true was created in the metrics step)
  # If skel_true[node_a, node_b] is FALSE, it means this edge is a False Positive.
  if (skel_true[node_a, node_b] == 0) {
    edge_colors[i] <- "red"     # Highlight in Red
    edge_widths[i] <- 2.5       # Make it thicker
  }
}

# 3. Apply attributes to the graph
E(g_aracne)$color <- edge_colors
E(g_aracne)$width <- edge_widths

# 4. Plot
plot(g_aracne, 
     layout = layout_with_graphopt, 
     main = "ARACNE: False Positives (Red)",
     
     # Node styling
     vertex.color = "lightyellow",
     vertex.frame.color = "orange",
     vertex.size = 10,
     vertex.label.cex = 0.7,
     vertex.label.color = "black",
     
     # Edge styling
     # Note: ARACNE edges are undirected, so arrows might look bidirectional
     edge.arrow.size = 0.3
)

# Legend
legend("topleft", legend=c("Correct (TP)", "False Positive (FP)"), 
       col=c("gray50", "red"), lty=1, lwd=c(1, 2.5), cex=0.8)
```


# 5. We Try to do the same analysis using miic and 3off2

## 5.a miic
